{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning a diffusion model\n",
    "\n",
    "In this notebook, you will be training a tiny diffusion model, track the training process with MLflow, and tune the hyperparameters using Ray Tune.\n",
    "\n",
    "## A lightning tour of diffusion models.\n",
    "\n",
    "Surely, you have heard of diffusion models. It's the architecture behind DALL-E, Stable Diffusion and many others.\n",
    "Here we are going to look at a particular class of diffusion models, Denoising Diffusion Probabilistic Models (DDPM).\n",
    "\n",
    "DDPMs aim to generate high-quality samples from a given distribution, typically modeled as an image distribution. These models are based on the idea of denoising a sequence of noisy samples to reach the target distribution. Let's break down the mathematical explanation of DDPM.\n",
    "\n",
    "1. **Foward Diffusion Process:**\n",
    "   DDPM introduces a diffusion process to model the generation of samples. It assumes that the data $x$ evolves over a series of steps from an easily generated distribution to the target distribution. This process is defined by a sequence of transformations:\n",
    "\n",
    "   $$ x_0 \\sim p(x_0) $$\n",
    "   $$ x_t = \\sqrt{1 - \\beta_t} \\cdot x_{t-1} + \\sqrt{\\beta_t} \\cdot \\epsilon_t $$\n",
    "\n",
    "   Here, $x_0$ is sampled from an easily generated distribution (e.g., a Gaussian distribution), and $\\epsilon_t$ is sampled from a fixed distribution (e.g., Gaussian). The parameter $\\beta_t$ controls the step size of the diffusion process.\n",
    "\n",
    "2. **Reverse Diffusion Process:**\n",
    "   At each step of the diffusion process, a noise-corrupted version of the data is obtained. The model is then trained to denoise this corrupted sample and estimate the conditional distribution $p_{\\theta}(x_t | x_{t-1})$. The denoising process is typically modeled using a neural network.\n",
    "\n",
    "   $$ p_{\\theta}(x_t | x_{t-1}) = \\mathcal{N}\\left(x_t; \\mu_{\\theta}(x_{t-1}), \\Sigma_{\\theta}(x_{t-1})\\right) $$\n",
    "\n",
    "   Here, $\\mu_{\\theta}$ and $\\Sigma_{\\theta}$ are functions parameterized by the neural network, which outputs the mean and standard deviation of the conditional distribution.\n",
    "\n",
    "3. **Training Procedure:**\n",
    "   During training, we corrupt input samples and train the model to de-noise the inputs again.\n",
    "\n",
    "4. **Sampling:**\n",
    "   Once the model is trained, sampling from the model involves running the diffusion process forward and denoising at each step to generate high-quality samples.\n",
    "\n",
    "In summary, DDPM combines the diffusion process with a denoising neural network to model complex distributions. The training involves optimizing the model parameters to denoise corrupted samples and generate samples from the target distribution. For an in-depth explanation, we recommend Lilian Weng's blog post [\"What are Diffusion Models?\"](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/) and the huggingface blog post [\"The Annotated Diffusion Model\"](https://huggingface.co/blog/annotated-diffusion).\n",
    "\n",
    "To train a DDPM, we need two components: a noise scheduler (that adds & removes noise) and a (denoising) model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise Scheduler\n",
    "\n",
    "DPPMs feature a forward and a backward diffusion process. The noise scheduler implements the steps for both processes, you can find its implementation in the next cell. \n",
    "\n",
    "#### Forward diffusion process\n",
    "\n",
    "In the forward diffusion process, a small amount of (Gaussian) noise is added in $T$ steps. This yields a sequence of noisy samples $x_1, \\dots, x_T$. The step size is controlled by the noise (or variance) schedule $\\{\\beta_t \\in (0, 1)\\}^T_{t=1}$.\n",
    "\n",
    "We will be using a linear noise schedule (the $\\beta$ are linearly spaced). Of course, plenty of other options exist.\n",
    "There's a handy closed-form formula for sampling $x_t$ at any time step, which uses the [reparametrization trick](https://lilianweng.github.io/posts/2018-08-12-vae/#reparameterization-trick): If we define $\\alpha_t = 1 - \\beta_t$ and $\\bar{\\alpha}_t = \\prod_{i=1}^t \\alpha_i$, it turns out that $x_t$ is given by\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_t = \\sqrt{\\bar{\\alpha}_t}\\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t}\\boldsymbol{\\epsilon} \\\\\n",
    "$$\n",
    "\n",
    "where $\\epsilon_t$ is some isotropic Gaussian noise. This is implemented in the `add_noise` method.\n",
    "\n",
    "#### Reverse diffusion process\n",
    "\n",
    "We can recreate the original sample $\\mathbf{x}_0$, if we manage to reverse the process and sample from $q(\\mathbf{x}_{t-1}\\vert \\mathbf{x}_t)$. Unfortunately, this is not feasible, so we need to learn some model $p_\\theta$ which runs the _denoising_ or _reverse diffusion process_: \n",
    "\n",
    "$$\n",
    "p_\\theta(\\mathbf{x}_{0:T}) = p(\\mathbf{x}_T) \\prod^T_{t=1} p_\\theta(\\mathbf{x}_{t-1} \\vert \\mathbf{x}_t) \\quad\n",
    "p_\\theta(\\mathbf{x}_{t-1} \\vert \\mathbf{x}_t) = \\mathcal{N}(\\mathbf{x}_{t-1}; \\boldsymbol{\\mu}_\\theta(\\mathbf{x}_t, t), \\boldsymbol{\\Sigma}_\\theta(\\mathbf{x}_t, t))\n",
    "$$\n",
    "\n",
    "The reverse diffusion process becomes tractable when we condition on $\\mathbf{x}_0$ and one can then derive [\"nice\"](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/#nice) equations for the reverse process, but we'll spare you the Gaussian jugglery.\n",
    "\n",
    "#### What really matters\n",
    "\n",
    "The details are not important for our application here. What _is_ important is that we already have three hyperparameters: The number of steps $T$ and the initial and final noise levels $\\beta_1$ and $\\beta_T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages directly with pip in current env\n",
    "%pip install -q jupyterlab_widgets\n",
    "%pip install -q ipywidgets\n",
    "%pip install -q data-morph-ai==0.2.0\n",
    "%pip install -q torch==2.6.0\n",
    "%pip install -q ray[tune]==2.41.0\n",
    "%pip install -q prophet==1.1.6\n",
    "%pip install -q mlflow==2.20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class NoiseScheduler:\n",
    "    def __init__(\n",
    "        self, T: int = 100, beta_0: float = 0.0001, beta_T: float = 0.02\n",
    "    ) -> None:\n",
    "        self.T = T\n",
    "        self.betas = torch.linspace(beta_0, beta_T, T)\n",
    "\n",
    "        # Reparametrization trick: alpha_t = 1 - beta_t\n",
    "        self.alphas = 1 - self.betas\n",
    "        # Cumulative product of alphas (the alpha with the bar in the text above).\n",
    "        self.alphas_bar = torch.cumprod(self.alphas, 0)\n",
    "        # Shifted alpha_bar; this is just an implementation trick to avoid using the\n",
    "        # cumprod function at each iteration.\n",
    "        self.alpha_bars_prev = torch.cat([torch.tensor([1.0]), self.alphas_bar[:-1]])\n",
    "\n",
    "        # The coefficients for the forward process.\n",
    "        self.sqrt_alphas_bar = self.alphas_bar**0.5\n",
    "        self.sqrt_one_minus_alphas_bar = (1 - self.alphas_bar) ** 0.5\n",
    "\n",
    "        # The coefficients for the backward process.\n",
    "        self.sqrt_inv_alphas = torch.sqrt(1 / self.alphas)\n",
    "        self.epsilon_coeff = self.betas / torch.sqrt(1 - self.alphas_bar)\n",
    "        self.sigmas = torch.sqrt(\n",
    "            self.betas * (1.0 - self.alpha_bars_prev) / (1.0 - self.alphas_bar)\n",
    "        )\n",
    "\n",
    "    def add_noise(\n",
    "        self, x_0: torch.Tensor, epsilon: torch.Tensor, t: int\n",
    "    ) -> torch.Tensor:\n",
    "        return (\n",
    "            self.sqrt_alphas_bar[t] * x_0 + epsilon * self.sqrt_one_minus_alphas_bar[t]\n",
    "        )\n",
    "\n",
    "    def remove_noise(\n",
    "        self, x_t: torch.Tensor, epsilon: torch.Tensor, t: int\n",
    "    ) -> torch.Tensor:\n",
    "        mu_tilde_t = self.sqrt_inv_alphas[t] * (x_t - self.epsilon_coeff[t] * epsilon)\n",
    "        sigma_t = self.sigmas[t]\n",
    "        z = torch.randn_like(epsilon)\n",
    "        return mu_tilde_t + sigma_t * z\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoising model\n",
    "\n",
    "As mentioned above, the denoising model is required to drive reverse process. More sophisticated diffusion models will use elaborate methods to embed time and inputs. Here, we'll use a simple MLP and ignore these intricacies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int = 3,\n",
    "        hidden_dim: int = 64,\n",
    "        output_dim: int = 2,\n",
    "        num_hidden_layers: int = 2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "        for _ in range(num_hidden_layers):\n",
    "            self.layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "        self.layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: The (noisy) input sample .\n",
    "            t: The current time step.\n",
    "\n",
    "        Returns:\n",
    "            The de-noised input sample.\n",
    "        \"\"\"\n",
    "        t_tensor = torch.full((x.shape[0], 1), t, dtype=torch.float32)\n",
    "        x = torch.cat((x, t_tensor), dim=-1)\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = F.gelu(layer(x))\n",
    "        return self.layers[-1](x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extend our list of hyperparameters with the number of hidden layers and the hidden layer dimension.\n",
    "\n",
    "## Training a diffusion model\n",
    "\n",
    "Now that we have the model, we of course want to train it. For this we need data, and since we are on a tight time and GPU budget, we'll use 2D point clouds - ours has a peculiar shape. ðŸ¤” "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "zhaw_logo = pd.read_csv(\"data/zhaw_logo.csv\")\n",
    "points = zhaw_logo.assign(y=lambda df: -df.y)\n",
    "points -= points.mean()\n",
    "points /= points.std()\n",
    "points.plot(kind=\"scatter\", x=\"x\", y=\"y\", color=\"black\", s=1).axis(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset \n",
    "dataset = TensorDataset(\n",
    "    torch.tensor(points.values, dtype=torch.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training works as follows:\n",
    "\n",
    "1. Select a random time step $t$ between $0$ and $T-1$.\n",
    "2. Add noise to the input at $t$.\n",
    "3. Predict the noise using the model.\n",
    "4. Compute the loss.\n",
    "5. Backpropagate the loss.\n",
    "\n",
    "The training loop is implemented in the cell below, but lacks tracking. Add missing code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "#Â TODO: Import and set up MLflow\n",
    "\n",
    "config = {\n",
    "    \"epochs\": 10000,\n",
    "    \"batch_size\": 4196,\n",
    "    \"learning_rate\": 0.001,\n",
    "    # ... other hyperparameters ...\n",
    "}\n",
    "\n",
    "ddpm = MLP(input_dim=3, hidden_dim=64, output_dim=2, num_hidden_layers=3)\n",
    "noise_schedule = NoiseScheduler(T=10, beta_0=0.0001, beta_T=0.02)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "optimizer = torch.optim.Adam(ddpm.parameters(), lr=config[\"learning_rate\"])\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# TODO: Log hyperparameters and metrics with MLflow\n",
    "\n",
    "with tqdm(total=config[\"epochs\"]) as progress_bar:\n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        ddpm.train()\n",
    "        train_loss = 0\n",
    "        for batch in dataloader:\n",
    "            batch = batch[0]\n",
    "\n",
    "            # Select a random time step\n",
    "            t = torch.randint(low=0, high=len(noise_schedule), size=(1,)).item()\n",
    "\n",
    "            # Add noise to the batch\n",
    "            epsilon_target = torch.randn(batch.shape)\n",
    "            x_t_plus_1 = noise_schedule.add_noise(batch, epsilon_target, t)\n",
    "\n",
    "            # Predict the noise\n",
    "            epsilon_pred = ddpm(x_t_plus_1, t)\n",
    "\n",
    "            # Compute the loss: the difference between the predicted noise and the target noise\n",
    "            loss = criterion(epsilon_pred, epsilon_target)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(dataset)\n",
    "        #Â TODO: Log the loss with MLflow\n",
    "        progress_bar.set_postfix({\"loss\": f\"{train_loss:.4f}\"})\n",
    "        progress_bar.update(1)\n",
    "\n",
    "#Â TODO: Log the model and final loss with MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we sample the DDPM. BY moving the slider, you can step through the de-noising process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_last = torch.randn(5000, 2)\n",
    "samples = [x_last]\n",
    "for t in reversed(range(len(noise_schedule))):\n",
    "    with torch.no_grad():\n",
    "        residual = ddpm(samples[-1], t)\n",
    "    samples.append(noise_schedule.remove_noise(samples[-1], residual, t))\n",
    "\n",
    "def update_plot(t, show_line):\n",
    "    plt.clf()\n",
    "    plt.scatter(samples[t][:, 0], samples[t][:, 1], color='#0064a6', s=1)\n",
    "    if show_line:\n",
    "        plt.scatter(points['x'], points['y'], color='black', s=1)\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "\n",
    "slider = widgets.IntSlider(min=0, max=len(samples)-1, step=1, value=0)\n",
    "toggle_button = widgets.ToggleButton(value=False, description='Show ground truth')\n",
    "widgets.interact(update_plot, t=slider, show_line=toggle_button)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, our approach works, but it the model is not perfect yet. To improve on our first model, let's tune some hyperparameters. Below, you can find the template from the previous notebook on Ray Tune. Your tasks are the following:\n",
    "\n",
    "[Evaluating](https://huggingface.co/docs/diffusers/conceptual/evaluation) generative models is challenging. Here, we refrain from implementing any sophisticated method and instead ask you to implement the following: compute summary statistics (mean in $x$, mean in $y$, standard deviation in $x$, standard deviation in $y$) and aim for a model that reproduces the ones from the training data. As the training data is normalized, the means are both 0 and the standard deviations are 1.\n",
    "\n",
    "1. Implement the trainable by copying the training loop from above. Instead of logging directly to MLflow, use the MLflow logger introduced earlier. \n",
    "2. Select a range of hyperparameters to tune. Some good candidates are the learning rate, $T$, $\\beta_0$, $\\beta_T$, and the parameters of the MLP. Define your `search_space`.\n",
    "3. Select a search algorithm and optionally a scheduler. We tested `HEBO`, but you are free to choose.\n",
    "\n",
    "Enjoy! :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune, train\n",
    "\n",
    "\n",
    "def trainable(config):\n",
    "    # config is a dict containing the hyperparameters, it is a sample from the search space\n",
    "\n",
    "    # train your model using the hyperparameters\n",
    "    # ...\n",
    "    score = 0.5\n",
    "\n",
    "    # return the score\n",
    "    return {\"score\": score}\n",
    "\n",
    "\n",
    "# Define the search space\n",
    "search_space = {\n",
    "    # Your hyperparameters go here\n",
    "}\n",
    "\n",
    "# Select the search algorithm and its parameters\n",
    "# (e.g. Random Search, Bayesian Optimization, HyperBand, etc.; Searcher is the base class for all search algorithms)\n",
    "algo = tune.search.Searcher(\n",
    "    # Your search algorithm parameters go here\n",
    ")\n",
    "\n",
    "# Select the scheduler and its parameters\n",
    "# (e.g. HyperBand, ASHAScheduler, etc.; Scheduler is the base class for all schedulers)\n",
    "scheduler = tune.schedulers.TrialScheduler(\n",
    "    # Your scheduler parameters go here\n",
    ")\n",
    "\n",
    "# Define the tune_config\n",
    "tune_config = tune.TuneConfig(\n",
    "    # Name of the metric that the trainable returns\n",
    "    # and we want to optimize.\n",
    "    metric=\"score\",\n",
    "    # The mode can be \"min\" or \"max\"\n",
    "    mode=\"max\",\n",
    "    # The search algorithm\n",
    "    search_alg=algo,\n",
    "    # The scheduler\n",
    "    scheduler=scheduler,\n",
    "    #Â Number of times to sample from the hyperparameter space\n",
    "    num_samples=10,\n",
    ")\n",
    "\n",
    "# Define the run_config.\n",
    "run_config = train.RunConfig(stop={\"training_iteration\": 20})\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    trainable=trainable,\n",
    "    tune_config=tune_config,\n",
    "    run_config=run_config,\n",
    "    param_space=search_space,\n",
    ")\n",
    "\n",
    "# Start the search\n",
    "results = tuner.fit() # returns result grid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-lab-03",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
