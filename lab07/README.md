# ML Deployment - The Last Mile and beyond

As more enterprises and startups alike develop their AI capabilities, we’re seeing a common roadblock emerge — known as AI’s “last mile” problem. When machine learning engineers and data scientists refer to the
"last mile", they usually mean the steps required to make an AI application available for widespread use.

> The last mile describes the short geographical segment of delivery of communication and media services or the delivery of products to customers located in dense areas. Last mile logistics tend to be complex and costly to providers of goods and services who deliver to these areas. (Investopedia).

In this lab, we look at how to bridge the last gap - because your job as a data scientist is not over once a model trained. Concretely, this means, we seek to answer the questions:

- How to deploy a model?
- How to monitor models?
- How to explain model output to your users?

We will be using Seldon's open-source `MLServer` together with `alibi-detect` and `alibi-explain`.

|Topic|Link|
|:----|:---|
|Deployment with `MLServer`| [`mlserver.md`](./mlserver.md) |
|Detecting data drift with `alibi-detect`| [`alibi_detect.md`](./alibi_detect.md) |
|Explaining models with `alibi-explain`| [`alibi-explain.md`](./alibi_explain.md) |

